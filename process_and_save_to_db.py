#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ PostgreSQL
–í–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è Excel —Ñ–∞–π–ª–æ–≤, —Å–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î:
- detailed_reports - –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
- negative_complaints - –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –∂–∞–ª–æ–±—ã
- complaints_by_region - –∂–∞–ª–æ–±—ã –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
- regions_complaints_pivot - pivot —Ä–µ–≥–∏–æ–Ω—ã-–∂–∞–ª–æ–±—ã
- not_found_applications - –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞—è–≤–∫–∏
"""

import os
import re
import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
BASE_DIR = Path(__file__).parent
CONFIG_DIR = BASE_DIR / 'config'
load_dotenv(CONFIG_DIR / 'postgresql.env')

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': os.getenv('DB_PORT', '5432'),
    'database': os.getenv('DB_NAME', 'qayta_data'),
    'user': os.getenv('DB_USER', 'qayta_user'),
    'password': os.getenv('DB_PASSWORD', 'qayta_password_2026')
}

# –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
DROP_COLUMNS = [
    '–î–∞—Ç–∞_112',
    '“ö—û–Ω“ì–∏—Ä–æ“õ –¥–∞–≤–æ–º–∏–π–ª–∏–≥–∏',
    '–ë—Ä–∏–≥–∞–¥–∞–≥–∞ —É–∑–∞—Ç–∏–ª–≥–∞–Ω –≤–∞“õ—Ç',
    '“ö—û–Ω“ì–∏—Ä–æ“õ —è–∫—É–Ω–ª–∞–Ω–≥–∞–Ω –≤–∞“õ—Ç',
    '–°—Ç–∞—Ç—É—Å_112',
    '“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∏–ª—É–≤—á–∏ –§.–ò.–®',
    '–¢–µ–ª–µ—Ñ–æ–Ω_112',
    '–é–∑–∏ —Ä–∞–¥ —ç—Ç–≥–∞–Ω',
    '–ï—Å—Ç—å_–∂–∞–ª–æ–±–∞'
]

# –ö–æ–ª–æ–Ω–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è (17 –∫–æ–ª–æ–Ω–æ–∫)
KEEP_COLUMNS = [
    '“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç',
    '–†–µ–≥–∏–æ–Ω_112',
    '–°–ª—É–∂–±–∞_112',
    '–¢–µ–ª–µ—Ñ–æ–Ω_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π',
    '–ò–Ω—Ü–∏–¥–µ–Ω—Ç_112',
    '–ñ–∞–ª–æ–±–∞',
    '–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏',
    '–¢–µ–ª–µ—Ñ–æ–Ω_Sheets',
    '–î–∞—Ç–∞_–æ—Ç–∫—Ä—ã—Ç–∏—è',
    '–°–ª—É–∂–±–∞_Sheets',
    '–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ',
    '–î–∞—Ç–∞_–∑–∞–∫—Ä—ã—Ç–∏—è',
    '–ò–Ω—Ü–∏–¥–µ–Ω—Ç_Sheets',
    '–°—Ç–∞—Ç—É—Å_Sheets',
    '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π',
    '–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ',
    '–ö–∞—Ç–µ–≥–æ—Ä–∏—è'
]

DATE_COLUMN = '“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç'


def get_db_connection():
    """–°–æ–∑–¥–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
    return psycopg2.connect(**DB_CONFIG)


def classify_status(val):
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ç—É—Å–∞"""
    if pd.isna(val):
        return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
    text = str(val).strip().lower()
    if not text:
        return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
    
    negative_keywords = ['–æ—Ç—Ä–∏—Ü', '–Ω–µ–≥–∞—Ç–∏–≤', '–Ω–µ—É–¥–æ–≤', '–ø–ª–æ—Ö']
    positive_keywords = ['–ø–æ–ª–æ–∂', '–ø–æ–∑–∏—Ç–∏–≤', '—É–¥–æ–≤', '—Ö–æ—Ä–æ—à']
    neutral_keywords = ['–∑–∞–∫—Ä—ã—Ç', '–∑–∞–≤–µ—Ä', '–≤—ã–ø–æ–ª–Ω']
    no_contact = ['–Ω–µ –¥–æ–∑–≤–æ–Ω', '–Ω–µ–¥–æ–∑–≤–æ–Ω', '–Ω–µ –æ—Ç–≤–µ—á–∞', '–Ω–µ—Ç —Å–≤—è–∑']
    
    for kw in negative_keywords:
        if kw in text:
            return '–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ'
    for kw in positive_keywords:
        if kw in text:
            return '–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ'
    for kw in no_contact:
        if kw in text:
            return '–ù–µ –¥–æ–∑–≤–æ–Ω–∏–ª–∏—Å—å'
    for kw in neutral_keywords:
        if kw in text:
            return '–ó–∞—è–≤–∫–∞ –∑–∞–∫—Ä—ã—Ç–∞'
    
    return '–î—Ä—É–≥–æ–µ'


def clean_complaint(text):
    """–£–¥–∞–ª–∏—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å—ã 1./2./3./4. –∏–∑ –∂–∞–ª–æ–±"""
    if pd.isna(text) or not text:
        return ''
    text = str(text).strip()
    text = re.sub(r'^[1-4]\.\s*', '', text)
    return text


def load_data_from_db():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î"""
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...")
    conn = get_db_connection()
    
    query = """
        SELECT 
            f.fixation_id,
            f.card_number,
            f.call_date AS "“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç",
            r.region_name AS "–†–µ–≥–∏–æ–Ω_112",
            s.service_name AS "–°–ª—É–∂–±–∞_112",
            f.phone AS "–¢–µ–ª–µ—Ñ–æ–Ω_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π",
            f.incident_number AS "–ò–Ω—Ü–∏–¥–µ–Ω—Ç_112",
            f.complaint AS "–ñ–∞–ª–æ–±–∞",
            f.status AS "–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏",
            f.status_category AS "–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Å—Ç–∞—Ç—É—Å–∞",
            f.reason,
            f.description AS "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
            o.operator_name,
            f.source_file,
            f.collection_date AS "–î–∞—Ç–∞_–∑–∞–∫—Ä—ã—Ç–∏—è"
        FROM fixations f
        LEFT JOIN operators o ON f.operator_id = o.operator_id
        LEFT JOIN regions r ON f.region_id = r.region_id
        LEFT JOIN services s ON f.service_id = s.service_id
        ORDER BY f.call_date
    """
    
    df = pd.read_sql(query, conn)
    conn.close()
    
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –∏–∑ –ë–î")
    return df


def process_detailed_data(df):
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    print("\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    df_detailed = df.copy()
    
    # –ö–æ–ª–æ–Ω–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 
    required_cols = [
        '“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç',
        '–†–µ–≥–∏–æ–Ω_112',
        '–°–ª—É–∂–±–∞_112',
        '–¢–µ–ª–µ—Ñ–æ–Ω_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π',
        '–ò–Ω—Ü–∏–¥–µ–Ω—Ç_112',
        '–ñ–∞–ª–æ–±–∞',
        '–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏',
        '–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Å—Ç–∞—Ç—É—Å–∞',
        '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π',
        '–î–∞—Ç–∞_–∑–∞–∫—Ä—ã—Ç–∏—è'
    ]
    
    # –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    existing_cols = [col for col in required_cols if col in df_detailed.columns]
    df_detailed = df_detailed[existing_cols]
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—É
    if '“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç' in df_detailed.columns:
        df_detailed['“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç'] = pd.to_datetime(
            df_detailed['“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç'], 
            errors='coerce'
        )
        df_detailed = df_detailed.sort_values('“ö—û–Ω“ì–∏—Ä–æ“õ “õ–∞–±—É–ª “õ–∏–ª–∏–Ω–≥–∞–Ω –≤–∞“õ—Ç')
    
    # –î–æ–±–∞–≤–∏—Ç—å –Ω—É–º–µ—Ä–∞—Ü–∏—é
    df_detailed.insert(0, '‚Ññ', range(1, len(df_detailed) + 1))
    
    # –û—á–∏—Å—Ç–∏—Ç—å –∂–∞–ª–æ–±—ã –æ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
    if '–ñ–∞–ª–æ–±–∞' in df_detailed.columns:
        df_detailed['–ñ–∞–ª–æ–±–∞'] = df_detailed['–ñ–∞–ª–æ–±–∞'].apply(clean_complaint)
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å—Ç–∞—Ç—É—Å–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å
    if '–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Å—Ç–∞—Ç—É—Å–∞' not in df_detailed.columns and '–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏' in df_detailed.columns:
        df_detailed['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_—Å—Ç–∞—Ç—É—Å–∞'] = df_detailed['–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏'].apply(classify_status)
    
    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df_detailed):,} –∑–∞–ø–∏—Å–µ–π")
    return df_detailed


def create_negative_complaints(df_detailed):
    """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤ –∏ –∂–∞–ª–æ–±"""
    print("\n‚ùå –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤...")
    
    if '–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏' not in df_detailed.columns:
        return pd.DataFrame()
    
    # –ü–æ–∏—Å–∫ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ –∫–æ–ª–æ–Ω–∫–µ –°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏
    negative_keywords = ['–æ—Ç—Ä–∏—Ü', '–Ω–µ–≥–∞—Ç–∏–≤', '–Ω–µ—É–¥–æ–≤', '–ø–ª–æ—Ö', '–∂–∞–ª–æ–±']
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É
    mask = df_detailed['–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏'].fillna('').str.lower().apply(
        lambda x: any(kw in x for kw in negative_keywords) if x else False
    )
    
    df_negative = df_detailed[mask].copy()
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(df_negative):,} –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
    return df_negative


def create_complaints_by_region(df_detailed):
    """–°–æ–∑–¥–∞—Ç—å —Å–≤–æ–¥–∫—É –∂–∞–ª–æ–± –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º"""
    print("\nüó∫Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º...")
    
    if '–†–µ–≥–∏–æ–Ω_112' not in df_detailed.columns:
        return pd.DataFrame()
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º —Å –ø–æ–¥—Å—á–µ—Ç–æ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å—Ç–∞—Ç—É—Å–æ–≤
    summary = df_detailed.groupby('–†–µ–≥–∏–æ–Ω_112').agg({
        '–¢–µ–ª–µ—Ñ–æ–Ω_–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π': 'count'
    }).reset_index()
    
    summary.columns = ['–†–µ–≥–∏–æ–Ω', '–í—Å–µ–≥–æ_–∑–≤–æ–Ω–∫–æ–≤']
    
    # –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥—Å—á–µ—Ç –∂–∞–ª–æ–± (–∑–∞–ø–∏—Å–∏ —Å–æ —Å—Ç–∞—Ç—É—Å–æ–º —Å–æ–¥–µ—Ä–∂–∞—â–∏–º '–∂–∞–ª–æ–±')
    complaints_mask = df_detailed['–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏'].fillna('').str.lower().str.contains('–∂–∞–ª–æ–±', na=False)
    complaints_by_region = df_detailed[complaints_mask].groupby('–†–µ–≥–∏–æ–Ω_112').size().reset_index(name='–ñ–∞–ª–æ–±')
    
    summary = summary.merge(complaints_by_region, left_on='–†–µ–≥–∏–æ–Ω', right_on='–†–µ–≥–∏–æ–Ω_112', how='left')
    summary['–ñ–∞–ª–æ–±'] = summary['–ñ–∞–ª–æ–±'].fillna(0).astype(int)
    
    if '–†–µ–≥–∏–æ–Ω_112' in summary.columns:
        summary = summary.drop('–†–µ–≥–∏–æ–Ω_112', axis=1)
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ —Å–≤–æ–¥–∫–∞ –ø–æ {len(summary)} —Ä–µ–≥–∏–æ–Ω–∞–º")
    return summary


def create_regions_pivot(df_detailed):
    """–°–æ–∑–¥–∞—Ç—å pivot —Ç–∞–±–ª–∏—Ü—É —Ä–µ–≥–∏–æ–Ω—ã-–∂–∞–ª–æ–±—ã"""
    print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ pivot —Ç–∞–±–ª–∏—Ü—ã...")
    
    if '–†–µ–≥–∏–æ–Ω_112' not in df_detailed.columns or '–ñ–∞–ª–æ–±–∞' not in df_detailed.columns:
        return pd.DataFrame()
    
    # –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å –∂–∞–ª–æ–±–∞–º–∏
    df_complaints = df_detailed[df_detailed['–ñ–∞–ª–æ–±–∞'].notna() & (df_detailed['–ñ–∞–ª–æ–±–∞'] != '')].copy()
    
    if len(df_complaints) == 0:
        return pd.DataFrame()
    
    # –°–æ–∑–¥–∞—Ç—å pivot
    pivot = pd.crosstab(
        df_complaints['–†–µ–≥–∏–æ–Ω_112'],
        df_complaints['–ñ–∞–ª–æ–±–∞'],
        margins=True,
        margins_name='–ò–¢–û–ì–û'
    )
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω–∞ pivot —Ç–∞–±–ª–∏—Ü–∞ {pivot.shape[0]} x {pivot.shape[1]}")
    return pivot


def create_not_found_applications(df_detailed):
    """–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫"""
    print("\nüîç –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫...")
    
    # –ó–∞–ø–∏—Å–∏ –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∂–∞–ª–æ–±–∞—Ö –∏ —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º —Å—Ç–∞—Ç—É—Å–æ–º
    if '–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏' in df_detailed.columns:
        unknown_keywords = ['–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', '–¥—Ä—É–≥–æ–µ', '–æ—à–∏–±–∫–∞', '—Å–∏—Å—Ç–µ–º—ã']
        mask = df_detailed['–°—Ç–∞—Ç—É—Å_—Å–≤—è–∑–∏'].fillna('').str.lower().apply(
            lambda x: any(kw in x for kw in unknown_keywords) if x else False
        )
        df_not_found = df_detailed[mask].copy()
    else:
        df_not_found = pd.DataFrame()
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(df_not_found):,} –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞—è–≤–æ–∫")
    return df_not_found


def save_to_database(table_name, df, conn):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å DataFrame –≤ —Ç–∞–±–ª–∏—Ü—É PostgreSQL"""
    if len(df) == 0:
        print(f"‚ö†Ô∏è  –¢–∞–±–ª–∏—Ü–∞ {table_name} –ø—É—Å—Ç–∞—è, –ø—Ä–æ–ø—É—Å–∫...")
        return
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(df):,} –∑–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü—É {table_name}...")
    
    # –ó–∞–º–µ–Ω–∏—Ç—å NaT –∏ NaN –Ω–∞ None –¥–ª—è PostgreSQL
    df = df.replace({pd.NaT: None, pd.NA: None})
    df = df.where(pd.notna(df), None)
    
    cursor = conn.cursor()
    
    # –£–¥–∞–ª–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    cursor.execute(f"DROP TABLE IF EXISTS {table_name}")
    
    # –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É
    columns_def = []
    for col in df.columns:
        dtype = df[col].dtype
        if dtype == 'int64':
            sql_type = 'INTEGER'
        elif dtype == 'float64':
            sql_type = 'REAL'
        elif dtype == 'datetime64[ns]':
            sql_type = 'TIMESTAMP'
        else:
            sql_type = 'TEXT'
        
        col_name = col.replace(' ', '_').replace('‚Ññ', 'num')
        columns_def.append(f'"{col_name}" {sql_type}')
    
    create_query = f"""
        CREATE TABLE {table_name} (
            {', '.join(columns_def)}
        )
    """
    cursor.execute(create_query)
    
    # –í—Å—Ç–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    columns = [col.replace(' ', '_').replace('‚Ññ', 'num') for col in df.columns]
    values = [tuple(row) for row in df.values]
    
    insert_query = f"""
        INSERT INTO {table_name} ({', '.join([f'"{col}"' for col in columns])})
        VALUES %s
    """
    
    execute_values(cursor, insert_query, values)
    conn.commit()
    
    print(f"‚úì –¢–∞–±–ª–∏—Ü–∞ {table_name} —Å–æ–∑–¥–∞–Ω–∞ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*70)
    print("–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• –ò –°–û–•–†–ê–ù–ï–ù–ò–ï –í POSTGRESQL")
    print("="*70)
    
    start_time = datetime.now()
    
    try:
        # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        df = load_data_from_db()
        
        # 2. –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        df_detailed = process_detailed_data(df)
        
        # 3. –°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
        print("\n–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü...")
        df_negative = create_negative_complaints(df_detailed)
        
        # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–≤–∏—Å–∞—é—Ç
        # df_regions = create_complaints_by_region(df_detailed)
        # df_pivot = create_regions_pivot(df_detailed)
        df_not_found = create_not_found_applications(df_detailed)
        
        # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
        print("\n" + "="*70)
        print("–°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–ê–ó–£ –î–ê–ù–ù–´–•")
        print("="*70)
        
        conn = get_db_connection()
        
        save_to_database('detailed_reports', df_detailed, conn)
        save_to_database('negative_complaints', df_negative, conn)
        # skip: save_to_database('complaints_by_region', df_regions, conn)
        # skip: save_to_database('regions_complaints_pivot', df_pivot, conn)
        save_to_database('not_found_applications', df_not_found, conn)
        
        conn.close()
        
        # 5. –ò—Ç–æ–≥–∏
        elapsed = datetime.now() - start_time
        print("\n" + "="*70)
        print("‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("="*70)
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed}")
        print(f"\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã:")
        print(f"  ‚Ä¢ detailed_reports: {len(df_detailed):,} –∑–∞–ø–∏—Å–µ–π")
        print(f"  ‚Ä¢ negative_complaints: {len(df_negative):,} –∑–∞–ø–∏—Å–µ–π")
        print(f"  ‚Ä¢ not_found_applications: {len(df_not_found):,} –∑–∞–ø–∏—Å–µ–π")
        print("="*70)
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == '__main__':
    exit(main())
