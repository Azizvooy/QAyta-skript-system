#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
=============================================================================
–ö–û–ù–°–û–õ–ò–î–ò–†–û–í–ê–ù–ù–´–ô –ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–• –ò–ó GOOGLE SHEETS
=============================================================================
–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ 2-12 –∏–∑ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ –µ–¥–∏–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
=============================================================================
"""

import os
import sqlite3
from datetime import datetime
from pathlib import Path
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import socket
import pandas as pd

# –ü—Ä–æ–∫—Å–∏ (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Codespaces)
# os.environ['HTTP_PROXY'] = 'http://10.145.62.76:3128'
# os.environ['HTTPS_PROXY'] = 'http://10.145.62.76:3128'
# socket.setdefaulttimeout(120)

BASE_DIR = Path(__file__).parent
DB_PATH = BASE_DIR / 'data' / 'fiksa_database.db'
TOKEN_FILE = BASE_DIR / 'config' / 'token.json'
CREDENTIALS_FILE = BASE_DIR / 'config' / 'credentials.json'

SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# –°–ø–∏—Å–æ–∫ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
SPREADSHEET_IDS = [
    "18y_QSol_XIZiaKGdoc64-tqerxYXg1kwmO7mmxo21rQ",
    "1JG9RqC64MZbP63HCSa0avp55zXP8nEqzsiuQbbSi9Do",
    "1Ld37ljkNect6iLV0X0QztTJC7vhgPDkaRXTJGVYOtfg",
    "16AK6_7FcWeksg2KaLfuzxo6sOGxsORw9hU-lycgeGiM",
    "1h-EZltuaagu2dyFj0wf-lch2qIhXKaycyCM4MYwLa4U",
    "18WH4ocx371qXsuPIf00hvKR1Kc7u1cd2ZTOUsWS377U",
    "1iSH66bKucYRU7St8Ch_-NThYay3C-tD_p_VlLpVS7WA",
    "1toIzc0CpyQIditC9KqeMVf3II2CWAW4c96pqp1b1t6s",
    "1nrlXxHexPwEBJCyXUt6ehLSMUoC11A6tTr8B5MK1Tuw",
    "11cK2I6pQ_hrHMrbs0AhKmqLLiCbOV00R7tboG0CdrS0",
    "1-T0dKoRATQ4uWmYYli6qU7Jq9FvblD7AGW2wQZFoUB0",
    "10aFfdXjkLNlt_H0D9e4VJnxFJalGX5R9zLzAf8XpQDw",
    "1Gb0RJDqr-Z34D9dHXfPVcGJguKP46YKgPq1qgT_A4nI",
    "1-BdML7lK0fW3vrcxl8yTpgL9FpeM2NUotigf6JIN4CQ",
    "12EVYbShzbwujbqm42rkXZACrRbblo_2Ls-8XmUnID2I",
    "1YmNqdrkLeQBH5Nnq_gVdeVs3LDHArWXfHjo1BBYfpD4",
    "1mJfVK1dCSIMV4ME2lHXUyT1NXD0qaQgr_1pKqMPgCe4",
    "1MLsLwaimRSR6Gdhcm9fuatNs1B-kTgVDfUfbm6BSCjY",
    "12hSjYYlTj9DrVq4PTkI9IwTD4radEgG-Z0bYpgddXiU",
    "1_Ch5eolJHF5JQdSH7uLweBYvIZ1DomhED7pdWRdn7oI",
    "1uhvZlw1GEbMdDi5sGRJoPkd5tyvKnvob0XU0uKl99Z4",
    "1xohqcQR6vpLcmvWPNgbIPO1UCDQJmPILQ29yUpnH_A0",
    "1yDlr5nqVkoEpzPDdKRFyHTxSYJwnlyzBQ_NaJOev300",
    "1D6EIWhpH-QgjL1HvVqX54cQQl_52GJs0oAXWNQF8FKc",
    "1mP6RJtA918WUi8zq7N2RmPh4jMJfGa41UZT0mu3U4nQ",
    "1LbRFZb3830m77GKIBVipifmW6D0kCxWLP-Etku6sYts",
    "1XmQDC7hk0VYV1TQ9ETf9ZJfll5On41ZD2742H5fRmT0",
    "1j_VMVVb8CkM883y8nw2b1BHbTCCFw_43KkMZWhEK1SM",
    "1QMCAddnW5qn5OG9awAyI7Jqeo5Jzdh3mvEHuwqVBHsU",
    "1LjNHy0nsNqjeHRoAfCbGIRh_0QsLoSWSLPwRt4pik58",
    "1Ii1LlQRHtq8dqyZHCtFkCNti37fFK5ff9qbPxNHhcVw",
    "1S7oJBkx9NjsXramXxYeDq36zvN-3a--9f9KhhilfiNc",
    "1jJ8nz7lzFOgz40bN12kX1cyjkhCcquba6H9QHn8kldE",
    "1UaWDeG1pcNbGvvMrVSaRKGX6nqNdEmpQ92mueII1VRE",
    "1YuRCpm_iZkuK-eVqJ3EN5rCgEBOSgaY3qg5shaszb9A"
]

# –§–ò–û –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–∏—Å—Ç–æ–≤
FIO_LIST = [
    "Narziyeva Gavxar Atxamjanovna",
    "Xoshimov Akromjon Axmadjon o'g'li",
    "Farxodov Xusniddin Murodjon o'g'li",
    "Rahimjonov Kamoliddin Olimjon o'g'li",
    "Xusniddinova Shaxnoza Akramovna",
    "Qosimov Firdavs Nuriddin o'g'li",
    "Abdullayev Dilmurod Xayrulla o'g'li",
    "Sirojiddinov Ismoilbek Shavkat o'g'li",
    "Mavlyanova Dilobar Rustam qizi",
    "Zokirjonova Surayyo Rustam qizi",
    "Payziyeva Shoxista Navro'zjon qizi",
    "Muxamadaliyeva Mufazzal Abduqaxxorovna",
    "Turg'unboyeva Azizaxon Shuxrat qizi",
    "Ruziyeva Dilnoza Xoshimjonovna",
    "Sobirjonova Umidaxon Rustamovna",
    "Karimova Durdona Toir qizi",
    "Xasanova Maftuna Askar qizi",
    "Sagdullayeva Moxinur Asqar qizi",
    "Mirbabayeva Shirin Kaxramonovna"
]

# –õ–∏—Å—Ç—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
SHEETS_TO_IMPORT = ["FIKSA"]
for fio in FIO_LIST:
    SHEETS_TO_IMPORT.append(f"{fio} 01.2026")

print('\n' + '='*80)
print('üì• –ö–û–ù–°–û–õ–ò–î–ò–†–û–í–ê–ù–ù–´–ô –ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–• –ò–ó GOOGLE SHEETS')
print('='*80)
print(f'üìã –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(SPREADSHEET_IDS)}')
print(f'üìÑ –õ–∏—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞: {len(SHEETS_TO_IMPORT)}')
print('='*80)

def is_target_sheet(sheet_name):
    """–§–∏–ª—å—Ç—Ä –Ω—É–∂–Ω—ã—Ö –ª–∏—Å—Ç–æ–≤: FIKSA, FIKSA(...), –§–ò–û 01.2026"""
    if not sheet_name:
        return False
    name = str(sheet_name).strip()
    if name == 'FIKSA':
        return True
    if name.startswith('FIKSA'):
        return True
    if '01.2026' in name:
        return True
    return False

# =============================================================================
# –ê–£–¢–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø
# =============================================================================

def authenticate():
    """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Google API"""
    creds = None
    
    if TOKEN_FILE.exists():
        creds = Credentials.from_authorized_user_file(str(TOKEN_FILE), SCOPES)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            print('[AUTH] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞...')
            creds.refresh(Request())
        else:
            print('[AUTH] –ü–µ—Ä–≤–∏—á–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è (–∫–æ–Ω—Å–æ–ª—å–Ω—ã–π —Ä–µ–∂–∏–º)...')
            flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_FILE), SCOPES)
            auth_url, _ = flow.authorization_url(prompt='consent')
            print('\n–û—Ç–∫—Ä–æ–π—Ç–µ —Å—Å—ã–ª–∫—É –∏ –≤—Å—Ç–∞–≤—å—Ç–µ –∫–æ–¥ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏:')
            print(auth_url)
            code = os.environ.get('GOOGLE_AUTH_CODE')
            if not code:
                code = input('\n–ö–æ–¥ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: ').strip()
            flow.fetch_token(code=code)
            creds = flow.credentials
        
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
    
    return creds

# =============================================================================
# –ü–û–õ–£–ß–ï–ù–ò–ï –î–ê–ù–ù–´–•
# =============================================================================

def get_sheet_data(service, spreadsheet_id, sheet_name, max_rows=10000):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Å—Ç–∞"""
    try:
        # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å –ª–∏—Å—Ç
        range_name = f"'{sheet_name}'!A1:L{max_rows}"
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=range_name
        ).execute()
        
        values = result.get('values', [])
        return values
    except Exception as e:
        # –¢–∏—Ö–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—à–∏–±–∫–∏ (–ª–∏—Å—Ç –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å)
        return []

def get_all_sheet_names(service, spreadsheet_id):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ª–∏—Å—Ç–æ–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ —Å —Ä–∞–∑–º–µ—Ä–æ–º"""
    try:
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        sheets = spreadsheet.get('sheets', [])
        return [
            {
                'title': sheet['properties']['title'],
                'rowCount': sheet['properties'].get('gridProperties', {}).get('rowCount', 10000)
            }
            for sheet in sheets
        ]
    except:
        return []

def get_spreadsheet_title(service, spreadsheet_id):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        return spreadsheet.get('properties', {}).get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
    except:
        return f"ID: {spreadsheet_id[:8]}..."

def process_sheet_data_consolidated(values, sheet_name, doc_title, doc_id):
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ª–∏—Å—Ç–∞ - –≤–∑—è—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 2-12 (–∏–Ω–¥–µ–∫—Å—ã 1-11)
    –ò–ú–ü–û–†–¢–ò–†–£–ï–ú –í–°–ï –°–¢–†–û–ö–ò –ë–ï–ó –§–ò–õ–¨–¢–†–ê–¶–ò–ò
    """
    if not values or len(values) < 2:
        return []
    
    records = []
    
    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –±–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ —Å–æ —Å—Ç—Ä–æ–∫–∏ 2
    for row_idx, row in enumerate(values[1:], start=2):
        if not row or not any(row):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            continue
        
        # –ë–µ—Ä—ë–º –∫–æ–ª–æ–Ω–∫–∏ 2-12 (–∏–Ω–¥–µ–∫—Å—ã 1-11 –≤ Python)
        record = []
        for col_idx in range(1, 12):  # –ö–æ–ª–æ–Ω–∫–∏ 2-12 (–∏–Ω–¥–µ–∫—Å—ã 1-11)
            if col_idx < len(row):
                record.append(row[col_idx])
            else:
                record.append('')  # –ü—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∫—É –∏–º–ø–æ—Ä—Ç–∞ –≤ –∫–æ–ª–æ–Ω–∫—É L
        record.append('–î–∞')  # –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω–µ—Ü
        record.append(doc_title)  # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        record.append(sheet_name)  # –ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞
        record.append(doc_id)  # ID –¥–æ–∫—É–º–µ–Ω—Ç–∞
        record.append(row_idx)  # –ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
        
        records.append(record)
    
    return records

# =============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# =============================================================================

def main():
    try:
        # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
        print('\n[1/3] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Google Sheets...')
        creds = authenticate()
        service = build('sheets', 'v4', credentials=creds)
        print('‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ')
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        print(f'\n[2/3] –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ {len(SPREADSHEET_IDS)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')
        all_records = []
        stats = {
            'processed': 0,
            'success': 0,
            'errors': 0,
            'total_records': 0,
            'sheets_found': {}
        }
        
        for idx, spreadsheet_id in enumerate(SPREADSHEET_IDS, start=1):
            try:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc_title = get_spreadsheet_title(service, spreadsheet_id)
                print(f'\n  [{idx}/{len(SPREADSHEET_IDS)}] {doc_title}')
                
                # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –ª–∏—Å—Ç—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
                all_sheets = get_all_sheet_names(service, spreadsheet_id)
                
                doc_records = 0
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ö–ê–ñ–î–û–ì–û –ª–∏—Å—Ç–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
                for sheet_info in all_sheets:
                    sheet_name = sheet_info['title']
                    max_rows = sheet_info['rowCount']
                    values = get_sheet_data(service, spreadsheet_id, sheet_name, max_rows=max_rows)
                    
                    if values:
                        records = process_sheet_data_consolidated(
                            values, sheet_name, doc_title, spreadsheet_id
                        )
                        all_records.extend(records)
                        doc_records += len(records)
                        
                        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª–∏—Å—Ç–∞–º
                        if sheet_name not in stats['sheets_found']:
                            stats['sheets_found'][sheet_name] = 0
                        stats['sheets_found'][sheet_name] += len(records)
                        
                        if len(records) > 0:
                            print(f'    ‚úì {sheet_name}: {len(records)} –∑–∞–ø–∏—Å–µ–π')
                
                stats['processed'] += 1
                stats['success'] += 1
                stats['total_records'] += doc_records
                
                if doc_records > 0:
                    print(f'    –ò—Ç–æ–≥–æ: {doc_records} –∑–∞–ø–∏—Å–µ–π')
                
            except Exception as e:
                print(f'    ‚ùå –û—à–∏–±–∫–∞: {str(e)}')
                stats['errors'] += 1
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f'\n[3/3] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...')
        
        if all_records:
            # –°–æ–∑–¥–∞—ë–º DataFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            columns = [
                '–ö–æ–ª–æ–Ω–∫–∞_2', '–ö–æ–ª–æ–Ω–∫–∞_3', '–ö–æ–ª–æ–Ω–∫–∞_4', '–ö–æ–ª–æ–Ω–∫–∞_5', '–ö–æ–ª–æ–Ω–∫–∞_6',
                '–ö–æ–ª–æ–Ω–∫–∞_7', '–ö–æ–ª–æ–Ω–∫–∞_8', '–ö–æ–ª–æ–Ω–∫–∞_9', '–ö–æ–ª–æ–Ω–∫–∞_10', '–ö–æ–ª–æ–Ω–∫–∞_11', '–ö–æ–ª–æ–Ω–∫–∞_12',
                '–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω',
                '–î–æ–∫—É–º–µ–Ω—Ç', '–õ–∏—Å—Ç', 'ID_–î–æ–∫—É–º–µ–Ω—Ç–∞', '–ù–æ–º–µ—Ä_–°—Ç—Ä–æ–∫–∏'
            ]
            
            df = pd.DataFrame(all_records, columns=columns)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
            timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
            csv_file = BASE_DIR / 'data' / f'–ö–û–ù–°–û–õ–ò–î–ò–†–û–í–ê–ù–ù–´–ï_–î–ê–ù–ù–´–ï_{timestamp}.csv'
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            
            print(f'\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ CSV: {csv_file.name}')
            print(f'   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}')
            print(f'   –ö–æ–ª–æ–Ω–æ–∫: {len(columns)}')

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ SQLite
            try:
                DB_PATH.parent.mkdir(parents=True, exist_ok=True)
                conn = sqlite3.connect(DB_PATH)
                cur = conn.cursor()
                cur.execute('DROP TABLE IF EXISTS sheets_data')
                cur.execute('''
                    CREATE TABLE sheets_data (
                        –ö–æ–ª–æ–Ω–∫–∞_2 TEXT, –ö–æ–ª–æ–Ω–∫–∞_3 TEXT, –ö–æ–ª–æ–Ω–∫–∞_4 TEXT, –ö–æ–ª–æ–Ω–∫–∞_5 TEXT, –ö–æ–ª–æ–Ω–∫–∞_6 TEXT,
                        –ö–æ–ª–æ–Ω–∫–∞_7 TEXT, –ö–æ–ª–æ–Ω–∫–∞_8 TEXT, –ö–æ–ª–æ–Ω–∫–∞_9 TEXT, –ö–æ–ª–æ–Ω–∫–∞_10 TEXT, –ö–æ–ª–æ–Ω–∫–∞_11 TEXT, –ö–æ–ª–æ–Ω–∫–∞_12 TEXT,
                        –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω TEXT,
                        –î–æ–∫—É–º–µ–Ω—Ç TEXT, –õ–∏—Å—Ç TEXT, ID_–î–æ–∫—É–º–µ–Ω—Ç–∞ TEXT, –ù–æ–º–µ—Ä_–°—Ç—Ä–æ–∫–∏ INTEGER
                    )
                ''')
                conn.commit()

                batch_size = 5000
                rows = df.values.tolist()
                for i in range(0, len(rows), batch_size):
                    cur.executemany(
                        'INSERT INTO sheets_data VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)',
                        rows[i:i+batch_size]
                    )
                    conn.commit()
                conn.close()
                print(f'‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ SQLite: {DB_PATH.name}')
            except Exception as e:
                print(f'‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ SQLite: {e}')
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print('\n' + '='*80)
        print('‚úÖ –ò–ú–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù')
        print('='*80)
        print(f'\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:')
        print(f'  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats["processed"]}/{len(SPREADSHEET_IDS)}')
        print(f'  –£—Å–ø–µ—à–Ω–æ: {stats["success"]}')
        print(f'  –û—à–∏–±–æ–∫: {stats["errors"]}')
        print(f'  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {stats["total_records"]}')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ª–∏—Å—Ç–∞–º
        if stats['sheets_found']:
            print(f'\nüìÑ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –õ–ò–°–¢–ê–ú:')
            for sheet_name, count in sorted(stats['sheets_found'].items(), key=lambda x: x[1], reverse=True):
                if count > 0:
                    print(f'  {sheet_name[:50]:<50} - {count:>6} –∑–∞–ø–∏—Å–µ–π')
        
        print('\n' + '='*80)
        
    except Exception as e:
        print(f'\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}')
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
