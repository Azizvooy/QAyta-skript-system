#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
=============================================================================
–ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–• –ò–ó –ú–ù–û–ñ–ï–°–¢–í–ê GOOGLE SHEETS
=============================================================================
–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –ª–∏—Å—Ç–æ–≤ "–§–ò–û 01.2026" –∏ "FIKSA" –∏–∑ –≤—Å–µ—Ö —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
=============================================================================
"""

import os
import sqlite3
from datetime import datetime
from pathlib import Path
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import socket
import pandas as pd

# –ü—Ä–æ–∫—Å–∏
os.environ['HTTP_PROXY'] = 'http://10.145.62.76:3128'
os.environ['HTTPS_PROXY'] = 'http://10.145.62.76:3128'
socket.setdefaulttimeout(120)

BASE_DIR = Path(__file__).parent
DB_PATH = BASE_DIR / 'data' / 'fiksa_database.db'
TOKEN_FILE = BASE_DIR / 'config' / 'token.json'
CREDENTIALS_FILE = BASE_DIR / 'config' / 'credentials.json'

SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# –°–ø–∏—Å–æ–∫ ID –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
SPREADSHEET_IDS = [
    "18y_QSol_XIZiaKGdoc64-tqerxYXg1kwmO7mmxo21rQ",
    "1JG9RqC64MZbP63HCSa0avp55zXP8nEqzsiuQbbSi9Do",
    "1Ld37ljkNect6iLV0X0QztTJC7vhgPDkaRXTJGVYOtfg",
    "16AK6_7FcWeksg2KaLfuzxo6sOGxsORw9hU-lycgeGiM",
    "1h-EZltuaagu2dyFj0wf-lch2qIhXKaycyCM4MYwLa4U",
    "18WH4ocx371qXsuPIf00hvKR1Kc7u1cd2ZTOUsWS377U",
    "1iSH66bKucYRU7St8Ch_-NThYay3C-tD_p_VlLpVS7WA",
    "1toIzc0CpyQIditC9KqeMVf3II2CWAW4c96pqp1b1t6s",
    "1nrlXxHexPwEBJCyXUt6ehLSMUoC11A6tTr8B5MK1Tuw",
    "11cK2I6pQ_hrHMrbs0AhKmqLLiCbOV00R7tboG0CdrS0",
    "1-T0dKoRATQ4uWmYYli6qU7Jq9FvblD7AGW2wQZFoUB0",
    "10aFfdXjkLNlt_H0D9e4VJnxFJalGX5R9zLzAf8XpQDw",
    "1Gb0RJDqr-Z34D9dHXfPVcGJguKP46YKgPq1qgT_A4nI",
    "1-BdML7lK0fW3vrcxl8yTpgL9FpeM2NUotigf6JIN4CQ",
    "12EVYbShzbwujbqm42rkXZACrRbblo_2Ls-8XmUnID2I",
    "1YmNqdrkLeQBH5Nnq_gVdeVs3LDHArWXfHjo1BBYfpD4",
    "1mJfVK1dCSIMV4ME2lHXUyT1NXD0qaQgr_1pKqMPgCe4",
    "1MLsLwaimRSR6Gdhcm9fuatNs1B-kTgVDfUfbm6BSCjY",
    "12hSjYYlTj9DrVq4PTkI9IwTD4radEgG-Z0bYpgddXiU",
    "1_Ch5eolJHF5JQdSH7uLweBYvIZ1DomhED7pdWRdn7oI",
    "1uhvZlw1GEbMdDi5sGRJoPkd5tyvKnvob0XU0uKl99Z4",
    "1xohqcQR6vpLcmvWPNgbIPO1UCDQJmPILQ29yUpnH_A0",
    "1yDlr5nqVkoEpzPDdKRFyHTxSYJwnlyzBQ_NaJOev300",
    "1D6EIWhpH-QgjL1HvVqX54cQQl_52GJs0oAXWNQF8FKc",
    "1mP6RJtA918WUi8zq7N2RmPh4jMJfGa41UZT0mu3U4nQ",
    "1LbRFZb3830m77GKIBVipifmW6D0kCxWLP-Etku6sYts",
    "1XmQDC7hk0VYV1TQ9ETf9ZJfll5On41ZD2742H5fRmT0",
    "1j_VMVVb8CkM883y8nw2b1BHbTCCFw_43KkMZWhEK1SM",
    "1QMCAddnW5qn5OG9awAyI7Jqeo5Jzdh3mvEHuwqVBHsU",
    "1LjNHy0nsNqjeHRoAfCbGIRh_0QsLoSWSLPwRt4pik58",
    "1Ii1LlQRHtq8dqyZHCtFkCNti37fFK5ff9qbPxNHhcVw",
    "1S7oJBkx9NjsXramXxYeDq36zvN-3a--9f9KhhilfiNc",
    "1jJ8nz7lzFOgz40bN12kX1cyjkhCcquba6H9QHn8kldE",
    "1UaWDeG1pcNbGvvMrVSaRKGX6nqNdEmpQ92mueII1VRE",
    "1YuRCpm_iZkuK-eVqJ3EN5rCgEBOSgaY3qg5shaszb9A"
]

# –§–ò–û –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–∏—Å—Ç–æ–≤
FIO_LIST = [
    "Narziyeva Gavxar Atxamjanovna",
    "Xoshimov Akromjon Axmadjon o'g'li",
    "Farxodov Xusniddin Murodjon o'g'li",
    "Rahimjonov Kamoliddin Olimjon o'g'li",
    "Xusniddinova Shaxnoza Akramovna",
    "Qosimov Firdavs Nuriddin o'g'li",
    "Abdullayev Dilmurod Xayrulla o'g'li",
    "Sirojiddinov Ismoilbek Shavkat o'g'li",
    "Mavlyanova Dilobar Rustam qizi",
    "Zokirjonova Surayyo Rustam qizi",
    "Payziyeva Shoxista Navro'zjon qizi",
    "Muxamadaliyeva Mufazzal Abduqaxxorovna",
    "Turg'unboyeva Azizaxon Shuxrat qizi",
    "Ruziyeva Dilnoza Xoshimjonovna",
    "Sobirjonova Umidaxon Rustamovna",
    "Karimova Durdona Toir qizi",
    "Xasanova Maftuna Askar qizi",
    "Sagdullayeva Moxinur Asqar qizi",
    "Mirbabayeva Shirin Kaxramonovna"
]

# –õ–∏—Å—Ç—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
SHEETS_TO_IMPORT = ["FIKSA"]  # –ë–∞–∑–æ–≤—ã–µ –ª–∏—Å—Ç—ã
# –î–æ–±–∞–≤–ª—è–µ–º –ª–∏—Å—Ç—ã —Å –§–ò–û + " 01.2026"
for fio in FIO_LIST:
    SHEETS_TO_IMPORT.append(f"{fio} 01.2026")

print('\n' + '='*80)
print('üì• –ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–• –ò–ó –ú–ù–û–ñ–ï–°–¢–í–ê GOOGLE SHEETS')
print('='*80)
print(f'üìã –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(SPREADSHEET_IDS)}')
print(f'üìÑ –õ–∏—Å—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞: {len(SHEETS_TO_IMPORT)} ({len(FIO_LIST)} –§–ò–û + FIKSA)')
print('='*80)

# =============================================================================
# –ê–£–¢–ï–ù–¢–ò–§–ò–ö–ê–¶–ò–Ø
# =============================================================================

def authenticate():
    """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –≤ Google API"""
    creds = None
    
    if TOKEN_FILE.exists():
        creds = Credentials.from_authorized_user_file(str(TOKEN_FILE), SCOPES)
    
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            print('[AUTH] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞...')
            creds.refresh(Request())
        else:
            print('[AUTH] –ü–µ—Ä–≤–∏—á–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è...')
            flow = InstalledAppFlow.from_client_secrets_file(str(CREDENTIALS_FILE), SCOPES)
            creds = flow.run_local_server(port=0)
        
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
    
    return creds

# =============================================================================
# –ü–û–õ–£–ß–ï–ù–ò–ï –î–ê–ù–ù–´–•
# =============================================================================

def get_sheet_data(service, spreadsheet_id, sheet_name):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ª–∏—Å—Ç–∞"""
    try:
        # –ß–∏—Ç–∞–µ–º –≤–µ—Å—å –ª–∏—Å—Ç
        range_name = f"'{sheet_name}'!A1:Z10000"
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=range_name
        ).execute()
        
        values = result.get('values', [])
        return values
    except Exception as e:
        print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–∏—Å—Ç–∞ '{sheet_name}': {str(e)}")
        return []

def get_spreadsheet_title(service, spreadsheet_id):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        spreadsheet = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()
        return spreadsheet.get('properties', {}).get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
    except:
        return f"ID: {spreadsheet_id[:8]}..."

def process_sheet_data(values, sheet_name, doc_title):
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —Å –ª–∏—Å—Ç–∞"""
    if not values or len(values) < 2:
        return []
    
    records = []
    headers = values[0] if values else []
    
    for idx, row in enumerate(values[1:], start=2):
        if not row or not any(row):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            continue
        
        # –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        record = {
            '–∏—Å—Ç–æ—á–Ω–∏–∫': doc_title,
            '–ª–∏—Å—Ç': sheet_name,
            '—Å—Ç—Ä–æ–∫–∞': idx,
            '–¥–∞—Ç–∞_–∏–º–ø–æ—Ä—Ç–∞': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç–æ–ª–±—Ü–æ–≤
        for col_idx, header in enumerate(headers):
            if col_idx < len(row):
                record[header] = row[col_idx]
        
        records.append(record)
    
    return records

# =============================================================================
# –°–û–•–†–ê–ù–ï–ù–ò–ï –í –ë–î
# =============================================================================

def save_to_database(all_records):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    if not all_records:
        print('\n‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è')
        return
    
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS imported_sheets_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            –∏—Å—Ç–æ—á–Ω–∏–∫ TEXT,
            –ª–∏—Å—Ç TEXT,
            —Å—Ç—Ä–æ–∫–∞ INTEGER,
            –¥–∞—Ç–∞_–∏–º–ø–æ—Ä—Ç–∞ TEXT,
            –¥–∞–Ω–Ω—ã–µ TEXT
        )
    ''')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∏
    added = 0
    for record in all_records:
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–ø–∏—Å—å –≤ JSON-—Å—Ç—Ä–æ–∫—É
            import json
            data_json = json.dumps(record, ensure_ascii=False)
            
            cursor.execute('''
                INSERT INTO imported_sheets_data 
                (–∏—Å—Ç–æ—á–Ω–∏–∫, –ª–∏—Å—Ç, —Å—Ç—Ä–æ–∫–∞, –¥–∞—Ç–∞_–∏–º–ø–æ—Ä—Ç–∞, –¥–∞–Ω–Ω—ã–µ)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                record.get('–∏—Å—Ç–æ—á–Ω–∏–∫', ''),
                record.get('–ª–∏—Å—Ç', ''),
                record.get('—Å—Ç—Ä–æ–∫–∞', 0),
                record.get('–¥–∞—Ç–∞_–∏–º–ø–æ—Ä—Ç–∞', ''),
                data_json
            ))
            added += 1
        except Exception as e:
            print(f"    ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–∏: {str(e)}")
    
    conn.commit()
    conn.close()
    
    print(f'\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö: {added} –∑–∞–ø–∏—Å–µ–π')

# =============================================================================
# –≠–ö–°–ü–û–†–¢ –í CSV
# =============================================================================

def export_to_csv(all_records):
    """–≠–∫—Å–ø–æ—Ä—Ç –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ CSV —Ñ–∞–π–ª"""
    if not all_records:
        return
    
    # –°–æ–∑–¥–∞—ë–º DataFrame
    df = pd.DataFrame(all_records)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    csv_file = BASE_DIR / 'data' / f'–ò–ú–ü–û–†–¢_–ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–•_SHEETS_{timestamp}.csv'
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    
    print(f'\nüìÑ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ CSV: {csv_file.name}')
    print(f'   –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}')

# =============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# =============================================================================

def main():
    try:
        # –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
        print('\n[1/3] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Google Sheets...')
        creds = authenticate()
        service = build('sheets', 'v4', credentials=creds)
        print('‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ')
        
        # –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        print(f'\n[2/3] –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ {len(SPREADSHEET_IDS)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...')
        all_records = []
        stats = {
            'processed': 0,
            'success': 0,
            'errors': 0,
            'total_records': 0
        }
        
        for idx, spreadsheet_id in enumerate(SPREADSHEET_IDS, start=1):
            try:
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc_title = get_spreadsheet_title(service, spreadsheet_id)
                print(f'\n  [{idx}/{len(SPREADSHEET_IDS)}] {doc_title}')
                
                doc_records = 0
                
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫–∞–∂–¥–æ–≥–æ –ª–∏—Å—Ç–∞
                for sheet_name in SHEETS_TO_IMPORT:
                    values = get_sheet_data(service, spreadsheet_id, sheet_name)
                    
                    if values:
                        records = process_sheet_data(values, sheet_name, doc_title)
                        all_records.extend(records)
                        doc_records += len(records)
                        print(f'    ‚úì {sheet_name}: {len(records)} –∑–∞–ø–∏—Å–µ–π')
                    else:
                        print(f'    - {sheet_name}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö')
                
                stats['processed'] += 1
                stats['success'] += 1
                stats['total_records'] += doc_records
                print(f'    –ò—Ç–æ–≥–æ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {doc_records} –∑–∞–ø–∏—Å–µ–π')
                
            except Exception as e:
                print(f'    ‚ùå –û—à–∏–±–∫–∞: {str(e)}')
                stats['errors'] += 1
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f'\n[3/3] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...')
        if all_records:
            save_to_database(all_records)
            export_to_csv(all_records)
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print('\n' + '='*80)
        print('‚úÖ –ò–ú–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù')
        print('='*80)
        print(f'\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:')
        print(f'  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {stats["processed"]}/{len(SPREADSHEET_IDS)}')
        print(f'  –£—Å–ø–µ—à–Ω–æ: {stats["success"]}')
        print(f'  –û—à–∏–±–æ–∫: {stats["errors"]}')
        print(f'  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {stats["total_records"]}')
        
        # –¢–û–ü-10 –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–ø–∏—Å–µ–π
        if all_records:
            from collections import Counter
            sources = [r['–∏—Å—Ç–æ—á–Ω–∏–∫'] for r in all_records]
            top_sources = Counter(sources).most_common(10)
            
            print(f'\nüèÜ –¢–û–ü-10 –î–û–ö–£–ú–ï–ù–¢–û–í –ü–û –ö–û–õ–ò–ß–ï–°–¢–í–£ –ó–ê–ü–ò–°–ï–ô:')
            for source, count in top_sources:
                print(f'  {source[:50]:<50} - {count} –∑–∞–ø–∏—Å–µ–π')
        
        print('\n' + '='*80)
        
    except Exception as e:
        print(f'\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {str(e)}')
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
